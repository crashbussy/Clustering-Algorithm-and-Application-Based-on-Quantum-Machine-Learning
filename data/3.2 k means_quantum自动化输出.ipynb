{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "#相比于最开始拿到的版本，qiskit更新了几处表达，\n",
    "#result.get_data（）改为result.data（），data的表达也有变化（可以print获得的data看看data不在表示为data['001']这样的形式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math lib\n",
    "from math import pi\n",
    "\n",
    "# import Qiskit\n",
    "from qiskit import Aer, execute#aer是模拟器\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "\n",
    "# import basic plot tools\n",
    "from qiskit.tools.visualization import plot_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use local qasm simulator  模拟器改了 之前是qasm\n",
    "backend = Aer.get_backend('aer_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta(d):\n",
    "    i = 0\n",
    "    theta = 0\n",
    "    count = 0\n",
    "    for i in d:\n",
    "        count = i+count\n",
    "   # print(d)\n",
    "    theta = 2*math.acos(count/384)\n",
    "   # print(theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Distance(x,y):\n",
    "    theta_1 = get_theta(x)\n",
    "    theta_2 = get_theta(y)\n",
    "    \n",
    "    # create Quantum Register called \"qr\" with 3 qubits\n",
    "    qr = QuantumRegister(3, name=\"qr\")\n",
    "    # create Classical Register called \"cr\" with 3 bits\n",
    "    cr = ClassicalRegister(1, name=\"cr\")\n",
    "\n",
    "    # Creating Quantum Circuit called \"qc\" involving your Quantum Register \"qr\"\n",
    "    # and your Classical Register \"cr\"\n",
    "    qc = QuantumCircuit(qr, cr, name=\"k_means\")\n",
    "    \n",
    "    qc.h(qr[0])\n",
    "    qc.h(qr[1])\n",
    "    qc.h(qr[2])\n",
    "    qc.u(theta_1, pi, pi, qr[1])\n",
    "    qc.u(theta_2, pi, pi, qr[2])\n",
    "    qc.cswap(qr[0], qr[1], qr[2])\n",
    "    qc.h(qr[0])\n",
    "\n",
    "    qc.measure(qr[0], cr[0])\n",
    "    qc.reset(qr)\n",
    "\n",
    "    #print('----before run----')\n",
    "    job = execute(qc,backend=backend, shots=1024)\n",
    "    #print('----after run----')\n",
    "    result = job.result()\n",
    "    data = result.data()['counts']\n",
    "    #print(data)\n",
    "    \n",
    "    if len(data)==1:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return data['0x1']/1024.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset_name,model_name,data_num):\n",
    "    import datasets\n",
    "    dataset = datasets.load_from_disk(dataset_name)\n",
    "    from sentence_transformers import SentenceTransformer \n",
    "    model = SentenceTransformer(model_name,cache_folder=r\"D:\\HF-model\\sentence-t5-base\")\n",
    "    from random import sample \n",
    "    import random\n",
    "    n = random.randint(1,999999)  \n",
    "    random.seed(n)\n",
    "    sentences = sample(dataset['test'][0]['sentences'],data_num) \n",
    "    random.seed(n) \n",
    "    labels =  sample(dataset['test'][0]['labels'],data_num)\n",
    "    embeddings = model.encode(sentences)#\n",
    "    points=embeddings\n",
    "    #print(type(points))\n",
    "    #初始化聚类中心\n",
    "    np.random.seed(96)\n",
    "    centroids = np.random.random([32,384])\n",
    "    return points,centroids,sentences,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(p1, p2):\n",
    "    #与经典没变化\n",
    "    return np.sqrt(np.sum((p1-p2)*(p1-p2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbour(points,centroids):\n",
    "    \n",
    "    n = len(points)\n",
    "    k = centroids.shape[0]\n",
    "    centers = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        min_dis = 10000\n",
    "        ind = 0#（Internodal Distance 节点间距离？）\n",
    "        for j in range(k):\n",
    "            #若这里为get_distance(points[i,:],centroids[j,:])则为经典算法\n",
    "            #这里只对最近邻计算做量子化处理。是否还有可能用量子计算机处理的地方？\n",
    "            \n",
    "            temp_dis = get_Distance(points[i,:],centroids[j,:])\n",
    "            \n",
    "            if temp_dis < min_dis:\n",
    "                min_dis = temp_dis\n",
    "                ind = j\n",
    "        centers[i] = ind\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids(points,centers):\n",
    "    n = len(points)\n",
    "    k = int(np.max(centers))+1\n",
    "   \n",
    "    centroids = np.zeros([k,384])\n",
    "    \n",
    "    for i in range(k):\n",
    "        #print(points[centers==i])\n",
    "        centroids[i,:] = np.average(points[centers==i])\n",
    "        \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(points):\n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    scaler = MinMaxScaler() \n",
    "    normalized_data = scaler.fit_transform(points)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n可选数据集：\\n'D:\\\\HF dataset\\\\mteb/arxiv-clustering-p2p'\\n'D:\\\\HF dataset\\\\mteb/arxiv-clustering-s2s'\\n'D:\\\\HF dataset\\\\mteb/biorxiv-clustering-p2p'\\n'D:\\\\HF dataset\\\\mteb/biorxiv-clustering-s2s'\\n'D:\\\\HF dataset\\\\mteb/medrxiv-clustering-s2s'\\n'D:\\\\HF dataset\\\\mteb/reddit-clustering'\\n'D:\\\\HF dataset\\\\mteb/reddit-clustering-p2p'\\n'D:\\\\HF dataset\\\\mteb/stackExchange-clustering'\\n'D:\\\\HF dataset\\\\mteb/stackExchange-clustering-p2p'\\n'D:\\\\HF dataset\\\\mteb/twentynewsgroups-clustering'\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "可选数据集：\n",
    "'D:\\HF dataset\\mteb/arxiv-clustering-p2p'\n",
    "'D:\\HF dataset\\mteb/arxiv-clustering-s2s'\n",
    "'D:\\HF dataset\\mteb/biorxiv-clustering-p2p'\n",
    "'D:\\HF dataset\\mteb/biorxiv-clustering-s2s'\n",
    "'D:\\HF dataset\\mteb/medrxiv-clustering-s2s'\n",
    "'D:\\HF dataset\\mteb/reddit-clustering'\n",
    "'D:\\HF dataset\\mteb/reddit-clustering-p2p'\n",
    "'D:\\HF dataset\\mteb/stackExchange-clustering'\n",
    "'D:\\HF dataset\\mteb/stackExchange-clustering-p2p'\n",
    "'D:\\HF dataset\\mteb/twentynewsgroups-clustering'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END******************************************************\n",
      "964.9289801120758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "d:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 85\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmteb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClusteringEvaluator\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m---> 85\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-t5-base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mHF-model\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msentence-t5-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m labels \u001b[38;5;241m=\u001b[39m centers\n\u001b[0;32m     87\u001b[0m clusterer \u001b[38;5;241m=\u001b[39m ClusteringEvaluator(sentences\u001b[38;5;241m=\u001b[39msentences, labels\u001b[38;5;241m=\u001b[39mlabels)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:95\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     87\u001b[0m         snapshot_download(model_name_or_path,\n\u001b[0;32m     88\u001b[0m                             cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m     89\u001b[0m                             library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m                             library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[0;32m     91\u001b[0m                             ignore_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflax_model.msgpack\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrust_model.ot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     92\u001b[0m                             use_auth_token\u001b[38;5;241m=\u001b[39muse_auth_token)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \u001b[38;5;66;03m#Load with AutoModel\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(model_path)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:840\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[1;34m(self, model_path)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_config \u001b[38;5;129;01min\u001b[39;00m modules_config:\n\u001b[0;32m    839\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m import_from_string(module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 840\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m     modules[module_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modules\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:137\u001b[0m, in \u001b[0;36mTransformer.load\u001b[1;34m(input_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(sbert_config_path) \u001b[38;5;28;01mas\u001b[39;00m fIn:\n\u001b[0;32m    136\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fIn)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Transformer(model_name_or_path\u001b[38;5;241m=\u001b[39minput_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:29\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_lower_case \u001b[38;5;241m=\u001b[39m do_lower_case\n\u001b[0;32m     28\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(tokenizer_name_or_path \u001b[38;5;28;01mif\u001b[39;00m tokenizer_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model_name_or_path, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_args)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#No max_seq_length set. Try to infer from model\u001b[39;00m\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:47\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[1;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the transformer model\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, T5Config):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_t5_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m AutoModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, config\u001b[38;5;241m=\u001b[39mconfig, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:55\u001b[0m, in \u001b[0;36mTransformer._load_t5_model\u001b[1;34m(self, model_name_or_path, config, cache_dir)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5EncoderModel\n\u001b[0;32m     54\u001b[0m T5EncoderModel\u001b[38;5;241m.\u001b[39m_keys_to_ignore_on_load_unexpected \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder.*\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mT5EncoderModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\modeling_utils.py:2276\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2273\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 2276\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_8bit:\n\u001b[0;32m   2279\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_keys_to_not_convert, replace_8bit_linear\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1770\u001b[0m, in \u001b[0;36mT5EncoderModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1768\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1769\u001b[0m encoder_config\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1770\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mT5Stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:848\u001b[0m, in \u001b[0;36mT5Stack.__init__\u001b[1;34m(self, config, embed_tokens)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m--> 848\u001b[0m     [T5Block(config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[0;32m    849\u001b[0m )\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:848\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m embed_tokens\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m--> 848\u001b[0m     [\u001b[43mT5Block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_layers)]\n\u001b[0;32m    849\u001b[0m )\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:634\u001b[0m, in \u001b[0;36mT5Block.__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mis_decoder\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList()\n\u001b[1;32m--> 634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(\u001b[43mT5LayerSelfAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39mappend(T5LayerCrossAttention(config))\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:564\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, has_relative_attention_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention \u001b[38;5;241m=\u001b[39m \u001b[43mT5Attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_relative_attention_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm \u001b[38;5;241m=\u001b[39m T5LayerNorm(config\u001b[38;5;241m.\u001b[39md_model, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlayer_norm_epsilon)\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mdropout_rate)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:347\u001b[0m, in \u001b[0;36mT5Attention.__init__\u001b[1;34m(self, config, has_relative_attention_bias)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_value_proj_dim\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# Mesh TensorFlow initialization to avoid scaling before softmax\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_dim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_dim, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Tool\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2359296 bytes."
     ]
    }
   ],
   "source": [
    "#range中的t1：想自动化出多少结果（每一遍都是同样大小数据集，但是选择的数据不同）\n",
    "#t2 为QKmeans算法中迭代次数\n",
    "\n",
    "t1 = 20\n",
    "t2 = 1\n",
    "\n",
    "for qq in range(10):\n",
    "    output = np.array([['v_measure','标签种类(k)']])\n",
    "        #选择数据集的模块\n",
    "    if qq==0:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/biorxiv-clustering-p2p'\n",
    "    if qq==1:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/biorxiv-clustering-s2s'\n",
    "    if qq==2:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/medrxiv-clustering-s2s'\n",
    "    if qq==3:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/reddit-clustering'\n",
    "    if qq==4:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/reddit-clustering-p2p'\n",
    "    if qq==5:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/stackExchange-clustering'\n",
    "    if qq==6:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/stackExchange-clustering-p2p'\n",
    "    if qq==7:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/twentynewsgroups-clustering'\n",
    "    if qq==8:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/arxiv-clustering-p2p'\n",
    "    if qq==9:\n",
    "        dataset_name = 'D:\\HF dataset\\mteb/arxiv-clustering-s2s'\n",
    "    \n",
    "        \n",
    "    #计时模块\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #QKmeans\n",
    "    for n1 in range(t1):\n",
    "\n",
    "        #设置超参数\n",
    "        model_name = 'sentence-t5-base'\n",
    "        data_num = 100\n",
    "    \n",
    "        points,centroids1,sentences,labels = get_data(dataset_name,model_name,data_num)       #dataset\n",
    "\n",
    "        points = preprocess(points)                # Normalize dataset\n",
    "        # run k-means algorithm\n",
    "        for i1 in range(t2):\n",
    "    \n",
    "            centers = find_nearest_neighbour(points,centroids1)       # find nearest centers\n",
    "            #print(centers)\n",
    "            centroids = find_centroids(points,centers)               # find centroids\n",
    "        \n",
    "        #一共有多少种不同的标签    \n",
    "        k=[0]*len(labels)\n",
    "        count = 0\n",
    "        #print(k)\n",
    "        flag1 = 0\n",
    "        for i in labels: \n",
    "            flag1 = 0 \n",
    "            for j in k: \n",
    "                if j == i: \n",
    "                    flag1 = 0\n",
    "                    break \n",
    "                else:  \n",
    "                    flag1 = 1\n",
    "            if flag1 == 1:\n",
    "                for n in range(len(labels)):\n",
    "                    if k[n] == 0:\n",
    "                        k[n] = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "        for m in k:\n",
    "            if m == 0:\n",
    "                break\n",
    "            else:\n",
    "                count = count + 1   \n",
    "        #print(len(k))\n",
    "        #print(k)\n",
    "        #count 是单个数字类型\n",
    "        #print('一共有多少种不同的标签：',count)\n",
    "    \n",
    "        #评价部分\n",
    "        from mteb.evaluation.evaluators import ClusteringEvaluator\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        model = SentenceTransformer('sentence-t5-base',cache_folder=r\"D:\\HF-model\\sentence-t5-base\")\n",
    "        labels = centers\n",
    "        clusterer = ClusteringEvaluator(sentences=sentences, labels=labels)\n",
    "        #result是dic类型\n",
    "        result = clusterer(model)\n",
    "        #print(result)\n",
    "        output = np.insert(output,n1+1,[str(result['v_measure']),str(count)],axis=0)\n",
    "    output = np.insert(output,0,[dataset_name[19:],str(data_num)],axis=0)\n",
    "\n",
    "    #计时模块\n",
    "    end_time = time.time()\n",
    "    cost_time = end_time - start_time\n",
    "\n",
    "    filename = '%s组重复 %s %s.csv'%(t1,dataset_name[19:],model_name)\n",
    "    np.savetxt(filename,output,fmt='%s',delimiter=',')\n",
    "    print('END******************************************************')\n",
    "    print(cost_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 学习块（load_dataset实验 保存到本地并使用）  \n",
    "为什么D:\\HF dataset\\mteb/arxiv-clustering-s2s   \n",
    "mteb后面一定要用反斜杠？？？？？？？？？？不用就识别的是mtebarxiv-clustering-s2s这样的路径\"\"\"\n",
    "#from datasets import load_dataset \n",
    "#dataset = load_dataset(\"mteb/arxiv-clustering-p2p\")\n",
    "#dataset.save_to_disk('D:\\HF dataset\\mteb/arxiv-clustering-p2p')\n",
    "#import datasets \n",
    "#dataset = datasets.load_from_disk(\"D:\\HF dataset\\mteb/arxiv-clustering-p2p\")\n",
    "\n",
    "\n",
    "\"\"\"修改网上下载数据集的缓存地址\"\"\"\n",
    "#from datasets import load_dataset\n",
    "#dataset = load_dataset('mteb/arxiv-clustering-p2p', cache_dir=\"D:\\HF .cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer     \n",
    "model = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['sentences', 'labels'],\n",
      "        num_rows: 31\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#评价模块\n",
    "from mteb.evaluation.evaluators import ClusteringEvaluator\n",
    "# Create ClusteringEvaluator instance\n",
    "evaluator = ClusteringEvaluator()\n",
    "# Evaluate the clustering results\n",
    "evaluation_result = evaluator.evaluate(centers) \n",
    "# Access evaluation metrics \n",
    "print(\"Adjusted Rand Index:\", evaluation_result[\"adjusted_rand_index\"]) \n",
    "print(\"Normalized Mutual Information:\", evaluation_result[\"normalized_mutual_information\"])\n",
    "print(\"Homogeneity Score:\", evaluation_result[\"homogeneity_score\"])\n",
    "print(\"Completeness Score:\", evaluation_result[\"completeness_score\"])\n",
    "print(\"V-Measure Score:\", evaluation_result[\"v_measure_score\"])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from mteb.evaluation.evaluators import ClusteringEvaluator \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "# Generate synthetic data for clustering X,\n",
    "np.random.seed(1)\n",
    "X = np.zeros((90, 3))#90行3列 \n",
    "#print(X) \n",
    "for i in range(X.shape[0]):   \n",
    "    if (i%3==0):        \n",
    "        x_dim = 2 + np.random.randn() # 围绕(2,3)作中心，随机散部点        \n",
    "        y_dim = 3 + np.random.randn()        \n",
    "        X[i, 0] = x_dim         \n",
    "        X[i, 1] = y_dim        \n",
    "        X[i, 2] = 0     \n",
    "    elif (i%3==1):         \n",
    "        x_dim = 4 + np.random.randn() # 围绕(4,5)作中心，随机散部点     \n",
    "        y_dim = 5 + np.random.randn()      \n",
    "        X[i, 0] = x_dim         \n",
    "        X[i, 1] = y_dim        \n",
    "        X[i, 2] = 1     \n",
    "    else:        \n",
    "        x_dim = 7 + np.random.randn() # 围绕(7,6)作中心，随机散部点        \n",
    "        y_dim = 6 + np.random.randn()      \n",
    "        X[i, 0] = x_dim       \n",
    "        X[i, 1] = y_dim      \n",
    "        X[i, 2] = 2        \n",
    "#print(X)\n",
    "# Cluster the data using K-means \n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "# Create ClusteringEvaluator instance\n",
    "evaluator = ClusteringEvaluator()\n",
    "# Evaluate the clustering results \n",
    "evaluation_result = evaluator.evaluate(y_pred)\n",
    "# Access evaluation metrics  \n",
    "print(\"Adjusted Rand Index:\", evaluation_result[\"adjusted_rand_index\"]) \n",
    "print(\"Normalized Mutual Information:\", evaluation_result[\"normalized_mutual_information\"])\n",
    "print(\"Homogeneity Score:\", evaluation_result[\"homogeneity_score\"])\n",
    "print(\"Completeness Score:\", evaluation_result[\"completeness_score\"]) \n",
    "print(\"V-Measure Score:\", evaluation_result[\"v_measure_score\"])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#构建MTEB 能够使用的模型（其实不需要，只要用MTEB 中的ClusteringEvaluator就能解决问题） \n",
    "from mteb import AbsTaskRetrieval, DRESModel \n",
    "class MyModel(DRESModel):       \n",
    "# Refer to the code of DRESModel for the methods to overwrite   \n",
    "    pass   \n",
    "assert AbsTaskRetrieval.is_dres_compatible(MyModel)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3-pytorch]",
   "language": "python",
   "name": "conda-env-Anaconda3-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
